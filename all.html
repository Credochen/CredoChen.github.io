<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	
  	
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
					
					<h1><a href="index.html"></a></h1>
					<p class="subtitle"></p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">













								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">
<div itemscope itemtype="http://schema.org/Blog">


	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-22T22:26:09+08:00" itemprop="datePublished">2016/12/22</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="aliyun-rds-data-trans.html" itemprop="url">
		上手阿里云RDS遇到的问题</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<blockquote>
<p>昨天购买了阿里云的RDS服务，准备将ECS上的MySQL数据迁移到RDS上，基于性能考虑。在这段测试的过程中，遇到了两个耗时很久才解决的问题。这里记录下。</p>
</blockquote>

<h2 id="toc_0">问题1. 相同地区，跨阿里云账号，内网无法连接rds。</h2>

<blockquote>
<p>问题描述<br/>
我有两个阿里云账号，就叫A和B吧，我在A账号下面购买了RDS服务，想要在B账号下面的ECS服务器内通过内网地址连接RDS。<br/>
在RDS里面已经加了IP白名单，IP地址都是内网IP。</p>
</blockquote>

<p>曾以为上iptables以及安全组的问题，试了很久都无法成功。最终通过工单解决了。</p>

<blockquote>
<p>您的ecs内部没有100.64段的路由<br/>
您看下这个连接<br/>
<a href="https://help.aliyun.com/knowledge_detail/41762.html">https://help.aliyun.com/knowledge_detail/41762.html</a> </p>
</blockquote>

<ul>
<li>问题原因：RDS的内网地址增加了100.64.0.0/10网段的地址</li>
<li><p>解决方法：</p>

<p>如果ECS没100.64.0.0/10路由记录，可以采用下面的方法进行修改：</p>

<p>Linux 相关系统添加方法参考：</p>

<p>注:下文的gateway_ip请根据实际情况替换<br/>
1）查看内网网关GATEWAY IP<br/>
    cat /etc/sysconfig/network-scripts/route-eth0<br/>
    下面的gateway_ip需要替换成上面查询得到的网关地址<br/>
2）手动添加静态路由规则，实时生效：<br/>
    ip route add 100.64.0.0/10 via gateway_ip dev eth0<br/>
3）添加静态路由到配置文件，持久化配置，下次重启系统也能生效：<br/>
    centos/redhat/alios/suse/opensuse 系统：<br/>
        echo &quot;100.64.0.0/10 via gateway_ip dev eth0” &gt;&gt; /etc/sysconfig/network-scripts/route-eth0<br/>
    ubuntu/debian 系统：<br/>
        echo &quot;up route add -net 100.64.0.0 netmask 255.192.0.0 gw gateway_ip dev eth0&quot; &gt;&gt; /etc/network/interfaces<br/>
    gentoo 系统：<br/>
        echo &quot;routes_eth0=(&quot;100.64.0.0/10 via gateway_ip&quot;)&quot; &gt;&gt; /etc/conf.d/net<br/>
4）检查路由是否设置成功：<br/>
    ip route show | grep &#39;100.64.0.0/10&#39; 100.64.0.0/10 via gateway_ip dev eth0</p></li>
</ul>

<h2 id="toc_1">问题2，在使用DTS迁移数据的时候，源数据库的账号如何配置合适</h2>

<blockquote>
<p>问题描述：在迁移数据的时候，选择“有公网ip的自建数据库”，<br/>
源库信息的主机名或IP地址，使用ecs的内网ip，然后ecs服务器上的迁移数据库账号，配置的主机是rds的内网地址是否可行？</p>
</blockquote>

<p>dts在迁移时并不是rds去连您的源,而是dts连的. 所以您配置host为rds的ip是不对的. 而dts又是一个集群,没有固定的ip,所以建议您配置host为%,就可以了，在配置的DTS的时候，源库信息的主机或ip地址填写数据的内网ip地址，就可以了。</p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-19T21:36:29+08:00" itemprop="datePublished">2016/12/19</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="stroing_mac_addr_in_mysql.html" itemprop="url">
		MySQL用什么类型的字段存储mac地址合适？</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>工作中遇到需要存储硬件的设备的mac地址，想到我们可以用<code>ip2long</code>,<code>long2ip</code>两个函数来存储和解析ip地址，那么mac地址应该也是可以的。</p>

<h2 id="toc_0">mac地址格式</h2>

<blockquote>
<p>MAC地址共48位（6个字节），以十六进制表示。比如： 01:23:45:67:78:AB</p>

<p>这意味着每个十六进制字段可以存储256（以10为基数的2的8的幂）值。 每个值为8位（= 1字节）。</p>
</blockquote>

<p>6 field x 8 bit = 48 bit = 6 bytes</p>

<h2 id="toc_1">数据库字段设计</h2>

<p>使用<code>bigint unsigned</code>存储。</p>

<blockquote>
<p>bigint 支持的数据范围：支持 -9223372036854775808到9223372036854775807(SIGNED)，0到18446744073709551615(UNSIGNED)，需要8个字节存储</p>
</blockquote>

<pre><code class="language-sql">-- 保存
INSERT INTO `devices` (mac_addr) VALUES (x&#39;0123456789AB&#39;);
-- 读取
SELECT HEX(mac_addr) FROM `devices`;
</code></pre>

<h2 id="toc_2">PHP处理</h2>

<pre><code class="language-php">function mac2int($mac) {
    return base_convert($mac, 16, 10);
}

function int2mac($int) {
    return base_convert($int, 10, 16);
}
// 更加人性化的读取
function int2macaddress($int) {
    $hex = base_convert($int, 10, 16);
    while (strlen($hex) &lt; 12)
        $hex = &#39;0&#39;.$hex;
    return strtoupper(implode(&#39;:&#39;, str_split($hex,2)));
}
</code></pre>

<ul>
<li>参考：<a href="http://www.onurguzel.com/storing-mac-address-in-a-mysql-database/">Storing MAC address in a MySQL database</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-11T21:23:24+08:00" itemprop="datePublished">2016/12/11</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="lets-encrypt.html" itemprop="url">
		获取Let's Encrypt的证书</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">获取CertBot</h2>

<pre><code class="language-bash">wget https://dl.eff.org/certbot-auto
chmod a+x certbot-auto
</code></pre>

<h2 id="toc_1">nginx 配置</h2>

<blockquote>
<p>针对不通的域名，都要有相应的配置。在Server下增加下面的location</p>
</blockquote>

<pre><code>location ^~ /.well-known/acme-challenge/ {
   default_type &quot;text/plain&quot;;
   root     /opt/openresty/nginx/html/;
}
location = /.well-known/acme-challenge/ {
   return 404;
}
</code></pre>

<h2 id="toc_2">获取证书</h2>

<pre><code class="language-bash">./certbot-auto certonly --email coder@example.com \
-w /opt/openresty/nginx/html/ -d example.domain.com \
--nginx --nginx-server-root /opt/openresty/nginx \
--nginx-ctl /usr/local/nginx/nginx
</code></pre>

<blockquote>
<p>--nginx-server-root NGINX_SERVER_ROOT<br/>
     Nginx server root directory. (default: /etc/nginx)<br/>
--nginx-ctl NGINX_CTL<br/>
     Path to the &#39;nginx&#39; binary, used for &#39;configtest&#39; and<br/>
     retrieving nginx version number. (default: nginx)</p>
</blockquote>

<h2 id="toc_3">自动续期--renew</h2>

<blockquote>
<p>Let&#39;s Encrypt 的证书有效期为 90 天，所以需要在到期前 renew 一下证书。</p>
</blockquote>

<pre><code class="language-bash"># 每隔 80 天的凌晨 4 点执行一次 renew：
0 4 */80 * * /root/certbot-auto certonly renew --email coder@example.com -w /var/www/html/open -d example.domain.com &amp;&gt;&gt; /tmp/certbot-renew.log
</code></pre>

<h2 id="toc_4">修改Nginx，启用Https</h2>

<pre><code class="language-bash">listen 443 ssl;
listen [::]:443 ssl ipv6only=on;# 如果服务器未启用ipv6，不要写这项配置
ssl_certificate /etc/letsencrypt/live/www.12301dev.com/fullchain.pem;
ssl_certificate_key /etc/letsencrypt/live/www.12301dev.com/privkey.pem;
ssl_trusted_certificate /etc/letsencrypt/live/www.12301dev.com/chain.pem;
</code></pre>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-11T21:22:04+08:00" itemprop="datePublished">2016/12/11</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql57-install.html" itemprop="url">
		Centos 6.5 编译安装MySQL 5.7</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">编译安装</h2>

<pre><code class="language-bash">cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql57 \
-DSYSCONFDIR=/usr/local/mysql57 \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci \
-DENABLED_LOCAL_INFILE=ON \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_ARCHIVE_STORAGE_ENGINE=1 \
-DWITH_FEDERATED_STORAGE_ENGINE=1 \
-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \
-DWITHOUT_EXAMPLE_STORAGE_ENGINE=1 \
-DWITH_PARTITION_STORAGE_ENGINE=1 \
-DWITH_PERFSCHEMA_STORAGE_ENGINE=1 \
-DWITH_READLINE=ON \
-DSYSCONFDIR=/data/mysql3326 \
-DWITH_BOOST=/usr/local/boost \
-DMYSQL_UNIX_ADDR=/data/mysql3326/mysql.sock

make -j #加cpu核心数可以更快！
make install
</code></pre>

<h2 id="toc_1">初始化数据(与5.6之前的初始化不同了！)</h2>

<pre><code class="language-bash">/usr/local/mysql57/bin/mysqld --defaults-file=/usr/local/mysql57/my.cnf --initialize 
# 这个时候可以看到一个root的初始密码，也会在error log里面

# 拷贝启动文件
cp support-files/mysql.server /etc/init.d/mysql57
# 修改权限
chmod u+x /etc/init.d/mysql57
# 启动
service mysql57 start

# 登录
mysql -uroot -p -S
</code></pre>

<h2 id="toc_2">后续操作</h2>

<pre><code class="language-sql">-- 修改初始密码
SET PASSWORD = PASSWORD(&#39;123456&#39;);
-- 增加权限
GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;127.0.0.1&#39; IDENTIFIED BY &#39;123467&#39; WITH GRANT OPTION;
</code></pre>

<h2 id="toc_3">参考</h2>

<p><a href="http://blog.csdn.net/yumushui/article/details/45534199">MySQL 5.7.7编译安装过程</a></p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-11T21:22:04+08:00" itemprop="datePublished">2016/12/11</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="http2-nginx.html" itemprop="url">
		HTTP/2 + nginx配置</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">申请免费的ssl证书</h2>

<p>可以参考<a href="./lets-encrypt.html">获取Let&#39;s Encrypt的证书</a></p>

<h2 id="toc_1">安装nginx</h2>

<pre><code class="language-bash">./configure --prefix=/usr/local/nginx \
--with-http_v2_module \
--with-http_ssl_module  \
--with-zlib=/data/software/zlib-1.2.8  \
--with-openssl=/data/software/openssl-1.0.2j \

make -j 4
make install
</code></pre>

<p><strong>要支持http/2，openssl版本必须要是1.0.2（或以上）</strong></p>

<h2 id="toc_2">配置</h2>

<pre><code class="language-bash">      listen       443 http2 ssl default_server;
    add_header Strict-Transport-Security &quot;max-age=63072000; includeSubdomains; preload&quot;;
    server_name  www.guangpeng.me;
    ssl_certificate /usr/loca/nginx/conf/certs/demo.crt;
    ssl_certificate_key /usr/loca/nginx/conf/certs/demo.key;
    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;
</code></pre>

<h2 id="toc_3">参考</h2>

<ul>
<li><a href="http://hectorguo.com/zh/http2-starter/">谈谈HTTP/2对前端的影响</a></li>
<li><a href="http://op.baidu.com/2015/04/https-s01a03/">大型网站的 HTTPS 实践（三）——基于协议和配置的优化</a></li>
<li><a href="https://linux.cn/article-5266-1.html">如何配置使用 HTTP 严格传输安全（HSTS）</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql-1.html" itemprop="url">
		《高性能MySQL》读书笔记——查询性能优化</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h3 id="toc_0">优化COUNT() 查询</h3>

<ul>
<li>列值统计时要求列值是非空的（不统计NULL）。当括号内指定了列或者列的表达式，则统计的就是这个表达式有值的结果数。</li>
<li>当MySQL确认括号内的表达式值不可能为空是，实际上就是在统计行数。——COUNT(*)。</li>
<li>如果希望知道的是结果集的行数，最好使用<strong>COUNT(*)</strong>。</li>
<li>关于MyISAM的神话

<ul>
<li>只有没有任何WHERE条件的<strong>COUNT(*)</strong>才非常快，因为此时无需实际地去计算表的行数。</li>
</ul></li>
</ul>

<hr/>

<ul>
<li>优化前：
<code>sql
SELECT COUNT(\*) FROM world.City WHERE id&gt;5
</code></li>
<li>优化后：
<code>sql
SELECT (SELECT COUNT(\*) FROM world.City) - COUNT(\*) FROM world.City
WHERE id&lt;=5
</code>
### 优化关联查询</li>
<li>确保ON或者USING字句中的列上有索引。</li>
<li>确保任何的GROUP BY 和ORDER BY 中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化这个过程</li>
</ul>

<h3 id="toc_1">优化子查询</h3>

<p><strong>尽可能</strong> 的使用关联查询代替。</p>

<h3 id="toc_2">优化GROUP BY 和DISTINCT</h3>

<p>采用查找表的标识列分组的效率会比其他列更高。</p>

<h3 id="toc_3">优化LIMIT分页</h3>

<blockquote>
<p>在偏移量非常大的时候，例如可能是LIMIT 10000，20这样的查询，这时MySQL需要查询10020条记录然后只返回20条，前面的10000条都将被抛弃。</p>
</blockquote>

<ul>
<li>要优化这种查询，要么是在页面中限制分页的数量，要么是优化大偏移量的性能。</li>
<li>一个最简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的列。然后根据需要做一次关联操作再返回所需的列。考虑下面的查询：
<code>sql
mysql&gt; SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50,5;
</code>
如果这张表非常大，那么下面的语句将大大提高效率。
<code>sql
mysql&gt; SELECT film_id, description FROM  sakila.film INNER JOIN (SELECT film_id FROM sakila.film ORDER BY title LIMIT 50,5) AS lim USING(film_id);
</code></li>
<li>LIMIT和OFFSET的问题，其实是OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上次数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样可以避免使用OFFSET。如：
<code>sql
mysql&gt; SELECT * FROM sakila.rental ORDER BY rental_id DESC LIMIT 20;
</code>
假设上面查询返回的主键为16049到16030，那么下一页的查询就可以从16030开始。
<code>sql
mysql&gt; SELECT * FROM sakila.rental WHERE rental_id&lt;16030 ORDER BY rental_id DESC LIMIT 20;
</code></li>
</ul>

<h3 id="toc_4">使用用户自定义变量</h3>

<p>避免重复查询刚刚更新的数据<br/>
<code>sql<br/>
    #bad sql<br/>
    mysql&gt; UPDATE t1 SET lastUpdate = NOW() WHERE id=1;<br/>
    mysql&gt; SELECT lastUpdate FROM t1  WHERE id=1<br/>
    #good sql<br/>
    mysql&gt; UPDATE t1 SET lastUpdate = NOW() WHERE id=1 AND @now := NOW();<br/>
    mysql&gt; SELECT @not;<br/>
</code></p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql-2.html" itemprop="url">
		《高性能MySQL》读书笔记——Schema与数据类型优化</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h3 id="toc_0">选择优化的数据类型</h3>

<ul>
<li>更小的通常更好：

<ul>
<li>更小的数据类型通常更快，因为它们占用更好的磁盘、内存和cpu缓存，并且处理时需要的cpu周期更少。</li>
<li><strong>但是要确保没有低估需要存储的值的范围；如果无法确定哪个数据类型是最好的，就选择自己认为不会超过范围的最小类型。</strong></li>
</ul></li>
<li>简单就好：

<ul>
<li>简单的数据类型的操作通常需要更少的cpu周期。</li>
<li>eg:整型 VS 字符型，应该使用MySQL内建的类型存储时间和日期而不是用字符串，应该使用整型存储IP地址。</li>
</ul></li>
<li>尽量避免NULL：

<ul>
<li>如果查询中包含可为NULL的列，可为NULL的列使得索引、索引统计的值比较都跟复杂；</li>
<li>可为NULL的列会使用更多的存储空间；</li>
<li>通常把可为NULL的列改为NOT NULL带来的性能提升比较小；</li>
<li>但是如果计划在列上建索引，就应该尽量避免设计成可为NULL的列。</li>
</ul></li>
</ul>

<h3 id="toc_1">选择数据类型</h3>

<blockquote>
<p>DATATIME和TIMESTAMP:<br /><br/>
DATETIME和TIMESTAMP都可以存储相同类型的数据，然而TIMESTAMP只使用DATETIME一半的存储空间，并且会根据时区变化，具有特殊的自动更新能力。另一方面，TIMESTAMP允许的时间范围要小的多。</p>
</blockquote>

<h3 id="toc_2">整数类型</h3>

<ul>
<li>TINYINT,SMALLINT,MEDIUMINT,INT,BIGINT，分别使用8,16,24,32,64位存储空间，它们可以存储的值的范围从pow(-2,N-1)到pow(2,(N-1)-1),其中N是存储空间的位数，pow()为PHP中的指数表达式。</li>
<li>整数类型有可选的UNSIGNED属性，表示不允许负值，这大致可以使整数的上线提高一倍。eg:TINYINT UNSIGEND可以存储的值的范围是0~255，而不加UNSIGNED的范围是-128~127。</li>
<li>MySQL可以为整数类型指定宽度，例如INT(11)，对大多数应用这是<strong>没有意义的</strong>：他不会限制值的范围，只是规定了MySQL的一些交互工具用来显示字符的个数。<strong>对于存储和计算来说，INT(1)和INT(20)是相同的</strong>。</li>
</ul>

<h3 id="toc_3">实数类型</h3>

<ul>
<li>实数是带有小数部分的数字。MySQL支持精确类型，也支持不精确类型。</li>
<li><strong>FLOAT</strong> 和 <strong>DOUBLE</strong> 类型支持使用标准的浮点运算进行近似计算。</li>
<li><strong>DECIMAL</strong> 类型用于存储精确的小数。</li>
<li>浮点和DECIMAL都可以指定精度。eg:DECIMAL(18,9)小数点两边将各存储9个数字，一共使用9个字节：小数点前的数字用4个字节，小数点后的用4个字节，小数点本身一个字节。</li>
</ul>

<h3 id="toc_4">字符串类型</h3>

<h5 id="toc_5">VARCHAR</h5>

<ul>
<li>VARCHAR 类型用于存储可边长字符串，比定长类型更省空间因为它仅使用必要的空间（eg.越短的字符串使用越少的空间）。<strong>有一种情况例外</strong>，如果MySQL表使用 ROW_FORMAT=FIXED 创建的话，没一行都会使用定长存储，这回很浪费空间。<br/></li>
<li><strong>VARCHAR需要使用1或2个额外的字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。</strong></li>
<li>适合使用VARCHAR的情况：

<ul>
<li>字符串列的最大长度比平均长度大很多；</li>
<li>列的更新少，所以碎片不是问题；</li>
<li>使用了像UTF-8复杂的字符集，每个字符都使用不同的字节数进行存储。</li>
</ul></li>
</ul>

<h5 id="toc_6">CHAR</h5>

<ul>
<li>CHAR 适合存储很短的字符串</li>
<li>对于经常变更的数据，CHAR也比VARCHAR更好，因为订单的CHAR类型不容易产生碎片；</li>
<li>对于非常短的列，CHAR比VARCHAR在存储空间上也更有效率。</li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="14812057029455.html" itemprop="url">
		函数-PHP下载文件</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<pre><code class="language-php">function dl_file($file){

   //First, see if the file exists
   if (!is_file($file)) { die(&quot;&lt;b&gt;404 File not found!&lt;/b&gt;&quot;); }

   //Gather relevent info about file
   $len = filesize($file);
   $filename = basename($file);
   $file_extension = strtolower(substr(strrchr($filename,&quot;.&quot;),1));

   //This will set the Content-Type to the appropriate setting for the file
  switch( $file_extension ) {
     case &quot;pdf&quot;: $ctype=&quot;application/pdf&quot;; break;
     case &quot;exe&quot;: $ctype=&quot;application/octet-stream&quot;; break;
     case &quot;zip&quot;: $ctype=&quot;application/zip&quot;; break;
     case &quot;doc&quot;: $ctype=&quot;application/msword&quot;; break;
     case &quot;xls&quot;: $ctype=&quot;application/vnd.ms-excel&quot;; break;
     case &quot;ppt&quot;: $ctype=&quot;application/vnd.ms-powerpoint&quot;; break;
     case &quot;gif&quot;: $ctype=&quot;image/gif&quot;; break;
     case &quot;png&quot;: $ctype=&quot;image/png&quot;; break;
     case &quot;jpeg&quot;:
     case &quot;jpg&quot;: $ctype=&quot;image/jpg&quot;; break;
     case &quot;mp3&quot;: $ctype=&quot;audio/mpeg&quot;; break;
     case &quot;wav&quot;: $ctype=&quot;audio/x-wav&quot;; break;
     case &quot;mpeg&quot;:
     case &quot;mpg&quot;:
     case &quot;mpe&quot;: $ctype=&quot;video/mpeg&quot;; break;
     case &quot;mov&quot;: $ctype=&quot;video/quicktime&quot;; break;
     case &quot;avi&quot;: $ctype=&quot;video/x-msvideo&quot;; break;

     //The following are for extensions that shouldn&#39;t be downloaded (sensitive stuff, like php files)
     case &quot;php&quot;:
     case &quot;htm&quot;:
     case &quot;html&quot;:
     case &quot;txt&quot;: die(&quot;&lt;b&gt;Cannot be used for &quot;. $file_extension .&quot; files!&lt;/b&gt;&quot;); break;

     default: $ctype=&quot;application/force-download&quot;;
   }

   //Begin writing headers
   header(&quot;Pragma: public&quot;);
   header(&quot;Expires: 0&quot;);
   header(&quot;Cache-Control: must-revalidate, post-check=0, pre-check=0&quot;);
   header(&quot;Cache-Control: public&quot;);
   header(&quot;Content-Description: File Transfer&quot;);

   //Use the switch-generated Content-Type
   header(&quot;Content-Type: $ctype&quot;);

   //Force the download
   $header=&quot;Content-Disposition: attachment; filename=&quot;.$filename.&quot;;&quot;;
   header($header );
   header(&quot;Content-Transfer-Encoding: binary&quot;);
   header(&quot;Content-Length: &quot;.$len);
   @readfile($file);
   exit;
}
</code></pre>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='fontend.html'>fontend</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="14812057029484.html" itemprop="url">
		Javascript 正则模板替换代码</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<pre><code class="language-javascript">function sub(str,data) {
    return str
        .replace(/{(.*?)}/igm,function($,$1) {
            return data[$1]?data[$1]:$;
        });
}
var json=[
    {
        name:&quot;Jim&quot;,
        blog:&quot;jim.com&quot;
    },
    {
        name:&quot;Tom&quot;,
        blog:&quot;tom.com&quot;
    },
    {
        name:&quot;Sam&quot;,
        blog:&quot;saam.com&quot;
    },
];

var tpl=&#39;{name} (blog: {blog})&#39;,
    html = &#39;&#39;;
for(var i = 0;i&lt;json.length;i++) {
    html += sub(tpl,json[i]);
}

console.log(html);
</code></pre>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql-3.html" itemprop="url">
		优化MySQL分页</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>之前写的SQL查询语句根本没有考虑到性能方面的问题，一是自己没有经验，二是因为网站规模小数据量不大，自然感受不到查询带来的性能问题。</p>

<p>最近由于数据量开始真大，在大后台一个产品列表的页面卡住了好久。最近也在阅读《高性能MYSQL》，就觉得将查询的语句优化下。废话结束。</p>

<hr/>

<ul>
<li><p>传统分页：</p>

<ul>
<li>SELECT * FROM table LIMIT 100000,10</li>
</ul></li>
<li><p>LIMIT的原理：</p>

<ul>
<li>LIMIT 偏移量，条数</li>
<li>当偏移量越大，速度越慢。</li>
</ul></li>
<li><p>推荐方法：</p>

<ul>
<li>SELECT * FROM table WHERE id&gt;=100000 LIMIT 11 #10+1 (每页10条);</li>
<li>SELECT * FROM table INNER JOIN (SELECT id FROM table LIMIT 100000,10) AS t USING(id);</li>
<li>SELECT * FROM table WHERE id&gt;=(SELECT id FROM table LIMIT 100000,1) LIMIT 10; </li>
<li>SELECT id FROM table LIMIT 100000,10;
SELECT * FROM table WHERE id IN(100,101...,110);</li>
</ul></li>
<li><p>其他：</p>

<ul>
<li>尽量不用SELECT * ，只取需要数据列 

<ul>
<li>更安全的设计：减少表变化带来的影响</li>
<li><strong>为使用covering index提供可能性</strong></li>
<li>Select/JOIN减少硬盘临时表生成，特别是有TEXT/BLOB时</li>
</ul></li>
</ul></li>
</ul>

<p>参考：<br/>
0.MySQL数据库开发的三十六条军规_石展_完整.pdf<br/>
1.<a href="http://blog.chinaunix.net/uid-26602509-id-3363512.html">**mysql LIMIT 子句用法及原理 **</a></p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:01:42+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql-iptable.html" itemprop="url">
		MySQL主从－从库开启iptabls无法同步</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>下班的时候检查数据库从服务器发现没有运行iptables服务，于是配置了有用到的端口后开启了iptables。<br/>
到家后有客服人员反应有订单查不到，第一反应是主从同步是失败了，立即开机检查。<br/>
<code>show slave status</code>,发现是正常的，所以想到了iptables，试着把iptable关了，过了一会数据又同步了。<br/>
定位到问题的所在，就容易解决了：<br/>
配置iptables，</p>

<pre><code class="language-shell"># vim /etc/sysconfig/iptables
-A OUTPUT -p tcp -m tcp --dport 3306 -j ACCEPT
</code></pre>

<p>重启iptables服务后正常。</p>

<p>参考：<br/>
<a href="http://www.cnblogs.com/JemBai/archive/2009/03/19/1416364.html">linux下IPTABLES配置详解</a></p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-08T22:00:45+08:00" itemprop="datePublished">2016/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="mysql56-install.html" itemprop="url">
		编译安装MySQL5.6</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h3 id="toc_0">安装编译代码需要的包</h3>

<pre><code class="language-shell">yum -y install make gcc-c++ cmake bison-devel  ncurses-devel
</code></pre>

<h3 id="toc_1">下载MySQL 5.6.14</h3>

<pre><code class="language-shell">wget http://cdn.mysql.com/Downloads/MySQL-5.6/mysql-5.6.14.tar.gz
tar xvf mysql-5.6.14.tar.gz
cd mysql-5.6.14
</code></pre>

<h3 id="toc_2">编译安装</h3>

<blockquote>
<p>编译的参数可以参考<a href="http://dev.mysql.com/doc/refman/5.5/en/source-configuration-options.html%E3%80%82">http://dev.mysql.com/doc/refman/5.5/en/source-configuration-options.html。</a></p>
</blockquote>

<pre><code class="language-shell">cmake \
-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \
-DMYSQL_DATADIR=/usr/local/mysql/data \
-DSYSCONFDIR=/etc \
-DWITH_MYISAM_STORAGE_ENGINE=1 \
-DWITH_INNOBASE_STORAGE_ENGINE=1 \
-DWITH_MEMORY_STORAGE_ENGINE=1 \
-DWITH_READLINE=1 \
-DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \
-DMYSQL_TCP_PORT=3306 \
-DENABLED_LOCAL_INFILE=1 \
-DWITH_PARTITION_STORAGE_ENGINE=1 \
-DEXTRA_CHARSETS=all \
-DDEFAULT_CHARSET=utf8 \
-DDEFAULT_COLLATION=utf8_general_ci

make &amp;&amp; make install
</code></pre>

<p>整个过程需要30分钟左右……漫长的等待</p>

<h3 id="toc_3">配置MySQL</h3>

<h4 id="toc_4">设置权限</h4>

<p>使用下面的命令查看是否有mysql用户及用户组</p>

<pre><code class="language-shell">cat /etc/passwd #查看用户列表
cat /etc/group  #查看用户组列表

groupadd mysql
useradd -g mysql mysql
# 修改/usr/local/mysql权限

chown -R mysql:mysql /usr/local/mysql
# 修改/usr/local/mysql权限

</code></pre>

<h4 id="toc_5">初始化配置</h4>

<p>进入安装路径</p>

<p><code>cd /usr/local/mysql</code><br/>
进入安装路径，执行初始化配置脚本，创建系统自带的数据库和表</p>

<p><code>scripts/mysql_install_db --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user=mysql</code></p>

<blockquote>
<p>注：在启动MySQL服务时，会按照一定次序搜索my.cnf，先在/etc目录下找，找不到则会搜索&quot;$basedir/my.cnf&quot;，在本例中就是 /usr/local/mysql/my.cnf，这是新版MySQL的配置文件的默认位置！</p>
</blockquote>

<p><strong>注意：在CentOS 6.4版操作系统的最小安装完成后，在/etc目录下会存在一个my.cnf，需要将此文件更名为其他的名字，如：/etc/my.cnf.bak，否则，该文件会干扰源码安装的MySQL的正确配置，造成无法启动。</strong></p>

<p>在使用&quot;yum update&quot;更新系统后，需要检查下/etc目录下是否会多出一个my.cnf，如果多出，将它重命名成别的。否则，MySQL将使用这个配置文件启动，可能造成无法正常启动等问题。</p>

<p>启动MySQL</p>

<ul>
<li>添加服务，拷贝服务脚本到init.d目录，并设置开机启动</li>
</ul>

<pre><code class="language-shell">cp support-files/mysql.server /etc/init.d/mysql
chkconfig mysql on
service mysql start  #启动MySQL
</code></pre>

<ul>
<li>配置用户</li>
</ul>

<p>MySQL启动成功后，root默认没有密码，我们需要设置root密码。</p>

<p>设置之前，我们需要先设置PATH，要不不能直接调用mysql</p>

<p>修改<code>/etc/profile</code>文件，在文件末尾添加</p>

<pre><code class="language-shell">PATH=/usr/local/mysql/bin:$PATH
export PATH
</code></pre>

<p>关闭文件，运行下面的命令，让配置立即生效</p>

<p><code>source /etc/profile</code><br/>
现在，我们可以在终端内直接输入mysql进入，mysql的环境了</p>

<p>执行下面的命令修改root密码</p>

<pre><code class="language-shell">mysql -uroot  
mysql&gt; SET PASSWORD = PASSWORD(&#39;123456&#39;);
</code></pre>

<p>若要设置root用户可以远程访问，执行</p>

<pre><code class="language-mysql&gt;">password为远程访问时，root用户的密码，可以和本地不同。

- 配置防火墙

防火墙的3306端口默认没有开启，若要远程访问，需要开启这个端口

打开`/etc/sysconfig/iptables`

在`-A INPUT –m state --state NEW –m tcp –p –dport 22 –j ACCEPT`，下添加：

`-A INPUT -m state --state NEW -m tcp -p -dport 3306 -j ACCEPT`
然后保存，并关闭该文件，在终端内运行下面的命令，刷新防火墙配置：

`service iptables restart`

OK，一切配置完毕，你可以访问你的MySQL了~

------------------------------------------------------------------------------------------------------------------

CentOS 7中默认使用Firewalld做防火墙，所以修改iptables后，在重启系统后，根本不管用。

Firewalld中添加端口方法如下：

firewall-cmd --zone=public --add-port=3306/tcp --permanent

firewall-cmd --reload


</code></pre>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-11-22T22:01:42+08:00" itemprop="datePublished">2016/11/22</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="supervisor-redis.html" itemprop="url">
		使用supervisor启动redis服务</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">缘起</h2>

<p>在服务器没有优化前，Web服务和Redis服务是同一台服务器，有一次系统遇到异常，导致Redis进程被干掉了。<br/>
因为Session是用Redis存储的，结果导致网站无法登录。（后来查了/var/log/message,发现是内存不够，系统自动杀死了耗内存的进程，连crontab服务也死了😢。<br/>
优化的方案是把Redis服务独立一台服务器，而且做了主从。之后服务稳定运行。<br/>
不够一直不解的问题是，Redis配置的内存是512M，不应该内存不够用的，Web服务用的内存也不多，无解。</p>

<h2 id="toc_1">配置</h2>

<ul>
<li><p>安装supervisor</p>

<ul>
<li><code>yum install python-setuptools</code></li>
<li><code>easy_install supervisor</code></li>
<li><code>supervisord -c /etc/supervisord.conf</code></li>
<li><code>vim /etc/supervisord.conf</code>，配置读取的配置文件位置<code>[include]</code>，修改：<code>files = /etc/supervisord/*.conf</code></li>
</ul></li>
<li><p>添加Redis配置</p></li>
</ul>

<pre><code class="language-shell">[program:redis]
command = /opt/redis-3.0.7/src/redis-server  /opt/redis-3.0.7/redis-6679.conf
autostart=true
autorestart=true
startsecs=3
</code></pre>

<ul>
<li><p>如果报错如下<br/>
<code>shell<br/>
gave up: redis entered FATAL state, too many start retries too quickly<br/>
修改redis.conf的daemonize为no<br/>
</code></p></li>
<li><p>启动<code>supervisord -c /etc/supervisord.conf</code></p></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-11-08T22:01:42+08:00" itemprop="datePublished">2016/11/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="telegraf-infuxdb.html" itemprop="url">
		基于telegraf＋inlfuxDB搭建日志收集系统</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">介绍</h2>

<ul>
<li><p>InfluxDB</p>

<blockquote>
<p><a href="https://www.influxdata.com/">InfluxDB</a>用Go语言编写的一个开源分布式时序、事件和指标数据库，和传统是数据库相比有不少不同的地方。<br/>
类似的数据库有Elasticsearch、Graphite等。</p>
</blockquote></li>
<li><p>telegraf</p>

<blockquote>
<p>Telegraf 是一个用 Go 编写的代理程序，可收集系统和服务的统计数据，并写入到 InfluxDB 数据库。<br/>
Telegraf 具有内存占用小的特点，通过插件系统开发人员可轻松添加支持其他服务的扩展。</p>
</blockquote></li>
</ul>

<h2 id="toc_1">安装</h2>

<pre><code class="language-bash"># 安装influxDB
wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0.x86_64.rpm
sudo yum localinstall influxdb-1.0.0.x86_64.rpm
# 安装telegraf
wget https://dl.influxdata.com/telegraf/releases/telegraf-1.0.0.x86_64.rpm
sudo yum localinstall telegraf-1.0.0.x86_64.rpm
</code></pre>

<p>安装好后配置文件分别在 <code>/etc/influxdb/</code>,<code>/etc/telegraf</code>下</p>

<h2 id="toc_2">修改telegraf配置文件</h2>

<p><code>vim /etc/telegraf/telegraf.conf</code></p>

<pre><code class="language-bash"># 这里配置收集日至规则,如果日志格式不同可以配置多项
[[inputs.logparser]]
    files = [&quot;/var/log/test/tmp.log&quot;]
    from_beginning = true
    [inputs.logparser.grok]
         # grok patterns，可以参考logstash的grok
         patterns = [&quot;%{DATA:date} %{IPV4:ip} %{HOSTNAME:client} %{WORD:method}#%{PARAMS:params}&quot;]
         # 上面的规则匹配如下日志
         # 2016-09-11 10:59:03 127.0.0.1 localhost Order_Globle_Search#sid:,mid:,lid:,tid:,ltitle:,ttitle:,btime1:,etime1:,btime2:,etime2:,btime3:,etime3:,ordernum:6605350,oname:,otel:,s    tatus:,pays:,fromt:,orderby:1,sort:0,rstart:0,n:1,c:,ordermode:,payinfo:,pmode:

        # 类似于数据库的table名称
        measurement = &quot;soap_log&quot;
         # 这里定义自定义匹配规则，格式: 变量名 正则表达式，每行一个规则
        custom_patterns = &#39;&#39;&#39;
            PARAMS .*
        &#39;&#39;&#39;
 [[inputs.logparser]]
   files = [&quot;/var/log/test/tmp.log&quot;]
   from_beginning = true
     # nginx 访问日志格式
     patterns = [&quot;%{COMMON_LOG_FORMAT}&quot;]
      # 自定义匹配格式保存的文件位置
     custom_pattern_files = []
     ## Custom patterns can also be defined here. Put one pattern per line.
     custom_patterns = &#39;&#39;&#39;
        PARAMS .*
     &#39;&#39;&#39;

</code></pre>

<h2 id="toc_3">启动</h2>

<pre><code class="language-bash">service influxdb start
service telegraf start
</code></pre>

<p>打开influxdb的web后台地址(默认端口是8083)，选择数据库 telegraf，执行<code>show measurements</code> ,可以查看已有的表。如果配置文件只修改了<code>logparser</code> ，那么还可以看到cpu，disk等一些与系统相关的表，这也是telegraf收集的数据。</p>

<h2 id="toc_4">常用的查询语句</h2>

<ul>
<li>根据字段名称查询：<code>select * from test_access_log where words=~ /Dynamic_Price_And_Storage/</code></li>
<li>删除表:<code>drop MEASUREMENTS test_access_log</code></li>
<li># 基于telegraf＋inlfuxDB搭建日志收集系统</li>
</ul>

<h2 id="toc_5">介绍</h2>

<ul>
<li><p>InfluxDB</p>

<blockquote>
<p><a href="https://www.influxdata.com/">InfluxDB</a>用Go语言编写的一个开源分布式时序、事件和指标数据库，和传统是数据库相比有不少不同的地方。<br/>
类似的数据库有Elasticsearch、Graphite等。</p>
</blockquote></li>
<li><p>telegraf</p>

<blockquote>
<p>Telegraf 是一个用 Go 编写的代理程序，可收集系统和服务的统计数据，并写入到 InfluxDB 数据库。<br/>
Telegraf 具有内存占用小的特点，通过插件系统开发人员可轻松添加支持其他服务的扩展。</p>
</blockquote></li>
</ul>

<h2 id="toc_6">安装</h2>

<pre><code class="language-bash"># 安装influxDB
wget https://dl.influxdata.com/influxdb/releases/influxdb-1.0.0.x86_64.rpm
sudo yum localinstall influxdb-1.0.0.x86_64.rpm
# 安装telegraf
wget https://dl.influxdata.com/telegraf/releases/telegraf-1.0.0.x86_64.rpm
sudo yum localinstall telegraf-1.0.0.x86_64.rpm
</code></pre>

<p>安装好后配置文件分别在 <code>/etc/influxdb/</code>,<code>/etc/telegraf</code>下</p>

<h2 id="toc_7">修改telegraf配置文件</h2>

<p><code>vim /etc/telegraf/telegraf.conf</code></p>

<pre><code class="language-bash"># 这里配置收集日至规则,如果日志格式不同可以配置多项
[[inputs.logparser]]
    files = [&quot;/var/log/test/tmp.log&quot;]
    from_beginning = true
    [inputs.logparser.grok]
         # grok patterns，可以参考logstash的grok
         patterns = [&quot;%{DATA:date} %{IPV4:ip} %{HOSTNAME:client} %{WORD:method}#%{PARAMS:params}&quot;]
         # 上面的规则匹配如下日志
         # 2016-09-11 10:59:03 127.0.0.1 localhost Order_Globle_Search#sid:,mid:,lid:,tid:,ltitle:,ttitle:,btime1:,etime1:,btime2:,etime2:,btime3:,etime3:,ordernum:6605350,oname:,otel:,s    tatus:,pays:,fromt:,orderby:1,sort:0,rstart:0,n:1,c:,ordermode:,payinfo:,pmode:

        # 类似于数据库的table名称
        measurement = &quot;soap_log&quot;
         # 这里定义自定义匹配规则，格式: 变量名 正则表达式，每行一个规则
        custom_patterns = &#39;&#39;&#39;
            PARAMS .*
        &#39;&#39;&#39;
 [[inputs.logparser]]
   files = [&quot;/var/log/test/tmp.log&quot;]
   from_beginning = true
     # nginx 访问日志格式
     patterns = [&quot;%{COMMON_LOG_FORMAT}&quot;]
      # 自定义匹配格式保存的文件位置
     custom_pattern_files = []
     ## Custom patterns can also be defined here. Put one pattern per line.
     custom_patterns = &#39;&#39;&#39;
        PARAMS .*
     &#39;&#39;&#39;

</code></pre>

<h2 id="toc_8">启动</h2>

<pre><code class="language-bash">service influxdb start
service telegraf start
</code></pre>

<p>打开influxdb的web后台地址(默认端口是8083)，选择数据库 telegraf，执行<code>show measurements</code> ,可以查看已有的表。如果配置文件只修改了<code>logparser</code> ，那么还可以看到cpu，disk等一些与系统相关的表，这也是telegraf收集的数据。</p>

<h2 id="toc_9">常用的查询语句</h2>

<ul>
<li>根据字段名称查询：<code>select * from test_access_log where words=~ /Dynamic_Price_And_Storage/</code></li>
<li>删除表:<code>drop MEASUREMENTS test_access_log</code>
<img src="https://lh3.googleusercontent.com/-aZBC0POMiK0/WE1blywCAPI/AAAAAAAACZc/8ld2Wt15jOg/I/demo.png" alt="demo"/></li>
</ul>

<h2 id="toc_10">参考</h2>

<ul>
<li><a href="https://segmentfault.com/a/1190000000444617">InfluxDB 开源分布式时序、事件和指标数据库</a></li>
<li><a href="http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/grok.html">Grok正则捕获</a></li>
<li><a href="https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns">logstash 系统自带的grop规则(可以直接在telegraf中使用)</a></li>
<li><a href="https://github.com/kkos/oniguruma/blob/master/doc/RE">Oniguruma Regular Expressions Version 6.0.0</a></li>
</ul>

<p><img src="https://lh3.googleusercontent.com/-aZBC0POMiK0/WE1blywCAPI/AAAAAAAACZc/8ld2Wt15jOg/I/demo.png" alt="demo"/></p>

<h2 id="toc_11">参考</h2>

<ul>
<li><a href="https://segmentfault.com/a/1190000000444617">InfluxDB 开源分布式时序、事件和指标数据库</a></li>
<li><a href="http://udn.yyuap.com/doc/logstash-best-practice-cn/filter/grok.html">Grok正则捕获</a></li>
<li><a href="https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns">logstash 系统自带的grop规则(可以直接在telegraf中使用)</a></li>
<li><a href="https://github.com/kkos/oniguruma/blob/master/doc/RE">Oniguruma Regular Expressions Version 6.0.0</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-05-22T21:01:42+08:00" itemprop="datePublished">2016/5/22</time>
			</div>
			
			 
			
		</div>
		<h1 class="title" itemprop="name"><a href="elasticsearch-basic.html" itemprop="url">
		Elasticsearch入门</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h3 id="toc_0">install plugin</h3>

<ul>
<li><p>head</p>

<pre><code class="language-shell">plugin install mobz/elasticsearch-head  
</code></pre>

<p>​</p></li>
<li><p>kpof</p>

<pre><code class="language-shell">plug install lmenezes/elasticsearch-kopf/master
</code></pre>

<p>​</p></li>
</ul>

<h3 id="toc_1">与传统关系型数据库对比</h3>

<table>
<thead>
<tr>
<th>MySQL</th>
<th>Elasticsearch</th>
</tr>
</thead>

<tbody>
<tr>
<td>Database-数据库</td>
<td>Indices-索引</td>
</tr>
<tr>
<td>Tables-表</td>
<td>Types-类型</td>
</tr>
<tr>
<td>Rows-行</td>
<td>Documents-文档</td>
</tr>
<tr>
<td>Columns-列</td>
<td>Fields-</td>
</tr>
</tbody>
</table>

<h3 id="toc_2">配置说明</h3>

<blockquote>
<p>elasticsearch的config文件夹里面有两个配置文件：elasticsearch.yml和logging.yml，第一个是es的基本配置文件，第二个是日志配置文件，es也是使用log4j来记录日志的，所以logging.yml里的设置按普通log4j配置文件来设置就行了。下面主要讲解下elasticsearch.yml这个文件中可配置的东西。</p>
</blockquote>

<pre><code class="language-yaml">cluster.name: elasticsearch
#配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。

node.name: &quot;FranzKafka&quot;
#节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。

node.master: true
#指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。

node.data: true
#指定该节点是否存储索引数据，默认为true。

index.number_of_shards: 5
#设置默认索引分片个数，默认为5片。

index.number_of_replicas: 1
#设置默认索引副本个数，默认为1个副本。

path.conf: /path/to/conf
#设置配置文件的存储路径，默认是es根目录下的config文件夹。

path.data: /path/to/data
#设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：
path.data: /path/to/data1,/path/to/data2

path.work: /path/to/work
#设置临时文件的存储路径，默认是es根目录下的work文件夹。

path.logs: /path/to/logs
#设置日志文件的存储路径，默认是es根目录下的logs文件夹

path.plugins: /path/to/plugins
#设置插件的存放路径，默认是es根目录下的plugins文件夹

bootstrap.mlockall: true
#设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit-l unlimited`命令。

network.bind_host: 192.168.0.1
#设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。


network.publish_host: 192.168.0.1
#设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。

network.host: 192.168.0.1
#这个参数是用来同时设置bind_host和publish_host上面两个参数。

transport.tcp.port: 9300
#设置节点间交互的tcp端口，默认是9300。

transport.tcp.compress: true
#设置是否压缩tcp传输时的数据，默认为false，不压缩。

http.port: 9200
#设置对外服务的http端口，默认为9200。

http.max_content_length: 100mb
#设置内容的最大容量，默认100mb

http.enabled: false
#是否使用http协议对外提供服务，默认为true，开启。

gateway.type: local
#gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器，其它文件系统的设置方法下次再详细说。

gateway.recover_after_nodes: 1
#设置集群中N个节点启动时进行数据恢复，默认为1。

gateway.recover_after_time: 5m
#设置初始化数据恢复进程的超时时间，默认是5分钟。

gateway.expected_nodes: 2
#设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。

cluster.routing.allocation.node_initial_primaries_recoveries: 4
#初始化数据恢复时，并发恢复线程的个数，默认为4。

cluster.routing.allocation.node_concurrent_recoveries: 2
#添加删除节点或负载均衡时并发恢复线程的个数，默认为4。

indices.recovery.max_size_per_sec: 0
#设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。

indices.recovery.concurrent_streams: 5
#设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。

discovery.zen.minimum_master_nodes: 1
#设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）

discovery.zen.ping.timeout:  3s
#设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。

discovery.zen.ping.multicast.enabled:  false
#设置是否打开多播发现节点，默认是true。

discovery.zen.ping.unicast.hosts:  [&quot;host1&quot;, &quot;host2: port&quot;,&quot;host3[portX-portY]&quot;]
#设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点
</code></pre>

<h3 id="toc_3">集群搭建</h3>

<ul>
<li><p>es1</p>

<pre><code class="language-yaml">cluster.name: sccES
node.name: &quot;es01&quot;
node.master: true
node.data: true
bootstrap.mlockall: true
network.host: 192.168.1.106
network.publish_host: 192.168.1.106
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.108&quot;]   # 如果没有配置此项，节点将无法加入到master
</code></pre>

<p>​</p></li>
<li><p>es2</p>

<pre><code class="language-yaml">cluster.name: sccES
node.name: &quot;es02&quot;
node.master: false
bootstrap.mlockall: true
network.host: 192.168.1.108
network.publish_host: 192.168.1.108
discovery.zen.ping.unicast.hosts: [&quot;192.168.1.106&quot;]  # 如果没有配置此项，节点将无法加入到master
</code></pre>

<p>​</p></li>
</ul>

<h3 id="toc_4">查询</h3>

<ul>
<li>复合查询</li>
</ul>

<pre><code class="language-json">{
    &quot;query&quot;:{
        &quot;filtered&quot;:{
            &quot;filter&quot;:{
                 &quot;range&quot;:{
                    &quot;age&quot;:{&quot;gt&quot;:25} /*条件1：年龄大于25*/
                }
            },
            &quot;query&quot;:{
                &quot;match&quot;:{
                    &quot;last_name&quot;:&quot;Chen&quot; /*条件2*/
                }
            }

        }
    }
}
</code></pre>

<ul>
<li><p>全文搜索</p>

<blockquote>
<p>默认情况下，Elasticsearch根据结果相关性评分来对结果集进行排序，所谓的「结果相关性评分」就是文档与查询条件的匹配程度</p>
</blockquote>

<pre><code class="language-json">{
&quot;query&quot;:{
    &quot;match&quot;:{
            &quot;abount&quot;: &quot;coding php&quot;
    }
}
}
</code></pre></li>
<li><p>短语搜索</p>

<pre><code class="language-json">{
  &quot;query&quot;:{
        &quot;match_phrase&quot;:{&quot;about&quot;:&quot;coding php&quot;}
    },
   &quot;highlight&quot;:{/*高亮显示，用&lt;em&gt;&lt;/em&gt;包裹*/
        &quot;fields&quot;:{
            &quot;about&quot;:{}
        }
    }
}
</code></pre></li>
<li><p>聚合(group by)</p>

<pre><code class="language-json">/*统计Li的所有兴趣*/
{
  &quot;query&quot;:{
      &quot;match&quot;:{
          &quot;last_name&quot;:&quot;Li&quot;
      }
  },
  &quot;aggs&quot;:{
      &quot;all_interests&quot;:{
          &quot;terms&quot;:{&quot;field&quot;:&quot;interests&quot;}
      }
  }
}
/*统计每种兴趣下职员的平均年龄*/
{
  &quot;aggs&quot;:{
      &quot;all_interests&quot;:{
          &quot;terms&quot;:{&quot;field&quot;:&quot;interests&quot;},
          &quot;aggs&quot;:{
              &quot;avg_age&quot;:{
                  &quot;avg&quot;:{&quot;field&quot;:&quot;age&quot;}
              }
          }
      }
  }
}
</code></pre>

<p>​</p></li>
</ul>

<h3 id="toc_5">参考资料</h3>

<ul>
<li><a href="http://es.xiaoleilu.com/index.html">Elasticsearch 权威指南（中文版）</a></li>
<li><a href="https://www.gitbook.com/book/endymecy/elasticsearch-guide-chinese/details">elasticsearch中文指南</a></li>
<li><a href="https://www.gitbook.com/book/pengqiuyuan/elkbook/details">日志收集与分析部署</a></li>
<li><a href="http://www.cnblogs.com/wgp13x/p/4859680.html">我的ElasticSearch集群部署总结--大数据搜索引擎你不得不知</a></li>
<li><a href="http://my.oschina.net/shyloveliyi/blog/653751">elasticsearch2.3.1 集群安装</a></li>
</ul>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2015-12-08T22:01:42+08:00" itemprop="datePublished">2015/12/8</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='lnmp.html'>lnmp</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="14812057029512.html" itemprop="url">
		查看 MySQL 数据库中每个表占用的空间大小</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>出处：<a href="http://www.oschina.net/question/12_3673">http://www.oschina.net/question/12_3673</a></p>

<blockquote>
<p>如果想知道MySQL数据库中每个表占用的空间、表记录的行数的话，可以打开MySQL的 information_schema 数据库。在该库中有一个 TABLES 表，这个表主要字段分别是：<br/>
TABLE_SCHEMA : 数据库名<br/>
TABLE_NAME：表名<br/>
ENGINE：所使用的存储引擎<br/>
TABLES_ROWS：记录数<br/>
DATA_LENGTH：数据大小<br/>
INDEX_LENGTH：索引大小<br/>
其他字段请参考MySQL的手册，我们只需要了解这几个就足够了。<br/>
所以要知道一个表占用空间的大小，那就相当于是 数据大小 + 索引大小 即可。<br/>
SQL:<br/>
<code>SELECT TABLE_NAME,DATA_LENGTH+INDEX_LENGTH,TABLE_ROWS FROM TABLES WHERE TABLE_SCHEMA=&#39;数据库名&#39; AND TABLE_NAME=&#39;表名&#39;</code></p>
</blockquote>

<ol>
<li>进去指定schema 数据库（存放了其他的数据库的信息）
<code>mysql
mysql&gt; use information_schema;
Database changed
</code></li>
<li>查询所有数据的大小
<code>mysql
mysql&gt; select concat(round(sum(DATA_LENGTH/1024/1024), 2), &#39;MB&#39;)
-&gt; as data from TABLES;
+-----------+
| data      |
+-----------+
| 6674.48MB |
+-----------+
1 row in set (16.81 sec)
</code></li>
<li>查看指定数据库的表的大小，比如说数据库 forexpert 中的 member 表
<code>mysql
select concat(round(sum(DATA_LENGTH/1024/1024), 2), &#39;MB&#39;)
as data from TABLES where table_schema=&#39;forexpert&#39;;
+--------+
| data   |
+--------+
| 2.52MB |
+--------+
1 row in set (1.88 sec)
</code></li>
<li>查看指定数据库实例的大小，比如说数据库 forexpert
<code>mysql
mysql&gt; select concat(round(sum(DATA_LENGTH/1024/1024), 2), &#39;MB&#39;)
-&gt; as data from TABLES where table_schema=&#39;forexpert&#39;;
+-----------+
| data      |
+-----------+
| 6542.30MB |
+-----------+
1 row in set (7.47 sec)
</code></li>
</ol>


			
			
		</div>

	</article>
  

</div>
<nav id="pagenavi">
	 
	
	<div class="center"><a href="archives.html">Blog Archives</a></div>

</nav>

</div>



        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    



</body>
</html>